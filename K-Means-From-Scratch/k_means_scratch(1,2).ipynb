{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BoFtKjERO6Q"
      },
      "source": [
        "####First, download a simulated dataset: kmeans_data.zip from Modules->Datasets. Then, implement the K-means algorithm from scratch. K-means algorithm computes the distance of a given data point pair. Replace the distance computation function with Euclidean distance, 1- Cosine similarity, and 1 â€“ the Generalized Jarcard similarity (refer to: https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/jaccard.htm)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### Q1: Run K-means clustering with Euclidean, Cosine and Jarcard similarity. Specify K= the number of categorical values of y (the number of classifications). Compare the SSEs of Euclidean-K-means, Cosine-K-means, Jarcard-K-means. Which method is better? (10 points)\n",
        "---"
      ],
      "metadata": {
        "id": "ohSC7CEYS8s6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_dWJomnvRO6S"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kWiWu5TDRO6U"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"/content/data.csv\",header=None).values\n",
        "\n",
        "label = pd.read_csv(\"/content/label.csv\",header=None).values.reshape(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_xkd9eMRO6Y",
        "outputId": "ab6eb854-fef5-4a90-b4ee-7f1d2ed30f24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ERhys4kRO6Y",
        "outputId": "ac6bc74b-ed92-4506-d9e0-b60775e845f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining distances/similarities"
      ],
      "metadata": {
        "id": "hWqPj9FTSRgI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uYKHZBafRO6a"
      },
      "outputs": [],
      "source": [
        "def euclidean_dist(a, b):\n",
        "    return np.linalg.norm(a - b)\n",
        "\n",
        "def cosine_sim(a, b):\n",
        "    return 1 - np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "\n",
        "def jaccard_sim(a, b):\n",
        "    return 1 - np.sum(np.minimum(a, b)) / np.sum(np.maximum(a, b))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-Means**"
      ],
      "metadata": {
        "id": "lBe_7moPTKJz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cU-L3z4XRO6b"
      },
      "outputs": [],
      "source": [
        "def k_means(data, k, sim, max_iterations=500):\n",
        "    centroids = random.sample(list(data), k)\n",
        "    iterations = 0\n",
        "    old_sse = 0\n",
        "    while True:\n",
        "        # Assign each data point to its closest centroid\n",
        "        clusters = [[] for i in range(k)]\n",
        "        for point in data:\n",
        "            distances = [sim(point, centroid) for centroid in centroids]\n",
        "            cluster_index = np.argmin(distances)\n",
        "            clusters[cluster_index].append(point)\n",
        "        \n",
        "        # Calculate the new centroid for each cluster\n",
        "        new_centroids = []\n",
        "        sse = 0\n",
        "        for i in range(k):\n",
        "            cluster = clusters[i]\n",
        "            if len(cluster) == 0:\n",
        "                new_centroids.append(centroids[i])\n",
        "                continue\n",
        "            centroid = np.mean(cluster, axis=0)\n",
        "            new_centroids.append(centroid)\n",
        "            sse += np.sum([sim(point, centroid) for point in cluster])\n",
        "        \n",
        "        # Check for convergence\n",
        "        if np.allclose(new_centroids, centroids) or sse >= old_sse or iterations >= max_iterations:\n",
        "            break\n",
        "        \n",
        "        # Update the centroids and SSE\n",
        "        centroids = new_centroids\n",
        "        old_sse = sse\n",
        "        iterations += 1\n",
        "    \n",
        "    return clusters, centroids, sse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj-DLK02RO6c",
        "outputId": "4d3e9c6f-c499-4401-a513-5124290adae8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "k = len(np.unique(label))\n",
        "k"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "so k = 10"
      ],
      "metadata": {
        "id": "x5T6elr1UfE0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KZdVG_7NRO6d"
      },
      "outputs": [],
      "source": [
        "clusters_euclidean, centroids_euclidean, sse_euclidean = k_means(data, 10, euclidean_dist)\n",
        "\n",
        "clusters_cosine, centroids_cosine, sse_cosine = k_means(data, 10, cosine_sim)\n",
        "\n",
        "clusters_jaccard, centroids_jaccard, sse_jaccard = k_means(data, 10, jaccard_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osTC0-n-RO6e",
        "outputId": "573a14e1-a277-4c61-d849-132bc51c3863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSE with Euclidean distance:  16474295.675340524\n",
            "SSE with Cosine similarity:  2880.9134811848053\n",
            "SSE with Jaccard similarity:  6532.516498391192\n"
          ]
        }
      ],
      "source": [
        "print(\"SSE with Euclidean distance: \", sse_euclidean)\n",
        "print(\"SSE with Cosine similarity: \", sse_cosine)\n",
        "print(\"SSE with Jaccard similarity: \", sse_jaccard)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comment:**\n",
        "\n",
        "Cosine Similarity seems to be the better method."
      ],
      "metadata": {
        "id": "s9NuhYueXajC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0i8QJCaRO6f"
      },
      "source": [
        "---\n",
        "#### Compare the accuracies of Euclidean-K-means Cosine-K-means, Jarcard-K-means. First, label each cluster using the majority vote label of the data points in that cluster. Later, compute the predictive accuracy of Euclidean-K-means, Cosine-K-means, Jarcard-K-means. Which metric is better? (10 points)\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BG3kU6RmRO6f"
      },
      "outputs": [],
      "source": [
        "class KMeans:\n",
        "    def __init__(self, k=10, max_iter=100, distance=euclidean_dist):\n",
        "        self.k = k\n",
        "        self.max_iter = max_iter\n",
        "        self.distance = distance\n",
        "    \n",
        "    def fit(self, X):\n",
        "        self.centroids = X[np.random.choice(X.shape[0], self.k, replace=False)]\n",
        "        for i in range(self.max_iter):\n",
        "            clusters = [[] for _ in range(self.k)]\n",
        "            for x in X:\n",
        "                distances = [self.distance(x, c) for c in self.centroids]\n",
        "                cluster = np.argmin(distances)\n",
        "                clusters[cluster].append(x)\n",
        "            new_centroids = []\n",
        "            for cluster in clusters:\n",
        "                if len(cluster) == 0:\n",
        "                    new_centroids.append(np.zeros(X.shape[1]))\n",
        "                else:\n",
        "                    new_centroids.append(np.mean(cluster, axis=0))\n",
        "            if np.allclose(self.centroids, new_centroids):\n",
        "                break\n",
        "            self.centroids = new_centroids\n",
        "    \n",
        "    def predict(self, X):\n",
        "        distances = np.array([np.array([self.distance(x, c) for c in self.centroids]) for x in X])\n",
        "        return np.argmin(distances, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ab6UNPgdRO6x"
      },
      "outputs": [],
      "source": [
        "def Accuracy(predicted, actual):\n",
        "    count = 0\n",
        "    total = len(label)\n",
        "    for i in range(total):\n",
        "        if predicted[i] == actual[i]:\n",
        "            count += 1\n",
        "    return (count/total)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "PeVDWEpFRO6v"
      },
      "outputs": [],
      "source": [
        "k_euclid = KMeans(k=10, max_iter=100, distance=euclidean_dist)\n",
        "k_euclid.fit(data)\n",
        "euclid_predictions = k_euclid.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VTgswrjnRO6w"
      },
      "outputs": [],
      "source": [
        "k_cosine = KMeans(k=10, max_iter=100, distance=cosine_sim)\n",
        "k_cosine.fit(data)\n",
        "cosine_predictions = k_cosine.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SVRjvdsYRO6w"
      },
      "outputs": [],
      "source": [
        "k_jarc = KMeans(k=10, max_iter=100, distance=jaccard_sim)\n",
        "k_jarc.fit(data)\n",
        "jarc_predictions = k_jarc.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3V5J075RO6x",
        "outputId": "515f686c-9ef0-4ff1-aa5e-7790ed12b9f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy using Euclidean Distance: 1.78\n",
            "Accuracy using Cosine Similarity: 11.09\n",
            "Accuracy using Jaccard Similarity: 6.859999999999999\n"
          ]
        }
      ],
      "source": [
        "print(\"Accuracy using Euclidean Distance:\",Accuracy(euclid_predictions,label))\n",
        "print(\"Accuracy using Cosine Similarity:\",Accuracy(cosine_predictions,label))\n",
        "print(\"Accuracy using Jaccard Similarity:\",Accuracy(jarc_predictions,label))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comment:**\n",
        "\n",
        "\n",
        "Cosine similarity works better \n"
      ],
      "metadata": {
        "id": "0feagD2TYdPi"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}